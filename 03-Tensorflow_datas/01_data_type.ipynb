{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从numpy得到Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个numpy数组\n",
    "a = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(np.ones([2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(np.zeros([3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([1,2], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [3.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按列\n",
    "tf.convert_to_tensor([[2],[3]] ,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化为0\n",
    "tf.zeros([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.zeros([2,3])\n",
    "tf.zeros_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[9, 9, 9],\n",
       "       [9, 9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fill([2,3], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([7, 1, 4, 2, 8, 5, 9, 3, 0, 6], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Permutation\n",
    "idx = tf.range(10)\n",
    "tf.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([2, 3, 9, 4, 3, 2, 5, 4, 9, 1], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([10,784])\n",
    "b = tf.random.uniform([10], maxval=10, dtype=tf.int32)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码使用了 TensorFlow 的随机数生成函数来创建两个张量 `a` 和 `b`，它们分别具有不同的形状和数据类型。以下是对每一行代码的详细解释：\n",
    "\n",
    "### 第一行代码\n",
    "```python\n",
    "a = tf.random.normal([10,784])\n",
    "```\n",
    "这行代码生成了一个形状为 `[10, 784]` 的张量 `a`，其中的值是从标准正态分布（均值为 0，标准差为 1）中随机采样的。  \n",
    "- `tf.random.normal` 是 TensorFlow 提供的一个函数，用于生成服从正态分布的随机数。\n",
    "- 参数 `[10, 784]` 指定了张量的形状，其中 `10` 表示有 10 行，`784` 表示每行有 784 个元素。这种形状通常出现在机器学习任务中，例如处理图像数据时，每一行可能表示一个样本的特征向量。\n",
    "- 默认情况下，生成的随机数的均值为 0，标准差为 1。如果需要自定义均值或标准差，可以通过 `mean` 和 `stddev` 参数进行设置。\n",
    "\n",
    "### 第二行代码\n",
    "```python\n",
    "b = tf.random.uniform([10], maxval=10, dtype=tf.int32)\n",
    "```\n",
    "这行代码生成了一个形状为 `[10]` 的张量 `b`，其中的值是从均匀分布中随机采样的整数。  \n",
    "- `tf.random.uniform` 是 TensorFlow 提供的另一个随机数生成函数，用于生成服从均匀分布的随机数。\n",
    "- 参数 `[10]` 指定了张量的形状，这里表示生成一个包含 10 个元素的一维张量。\n",
    "- `maxval=10` 指定了生成的随机数的上限（不包括 10），因此生成的整数范围是 `[0, 10)`。\n",
    "- `dtype=tf.int32` 指定了张量的数据类型为 32 位整数。如果不指定，默认生成的是浮点数。\n",
    "\n",
    "### 总结\n",
    "这两行代码通常用于深度学习任务中的数据准备阶段。例如，`a` 可以表示一个批次的输入数据，每一行是一个样本的特征向量；`b` 可以表示对应的标签，每个值是一个类别的整数编码。这种随机生成的数据常用于测试模型的输入输出逻辑或在没有真实数据时进行模拟实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 784), dtype=float32, numpy=\n",
       "array([[-0.5561249 ,  0.9767972 ,  1.2795693 , ..., -2.8483374 ,\n",
       "        -0.08515876, -0.05731236],\n",
       "       [ 1.0602908 , -1.213234  , -0.4027514 , ..., -1.8556712 ,\n",
       "         0.15543826,  0.48038015],\n",
       "       [ 0.21614434, -0.04368794, -0.7602156 , ..., -0.42578062,\n",
       "         0.09689245,  0.3449871 ],\n",
       "       ...,\n",
       "       [-1.6518344 , -1.5261984 , -0.62953895, ...,  1.0715771 ,\n",
       "         0.770145  ,  0.87259036],\n",
       "       [ 1.6307112 , -0.5472446 , -0.89111316, ..., -0.440326  ,\n",
       "         0.479541  ,  0.49390435],\n",
       "       [ 1.1130397 , -0.15136926,  0.39175627, ..., -0.48658842,\n",
       "         0.29421818,  0.5154033 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 tf.gather 函数根据索引张量 idx 从张量 a 中提取对应的行\n",
    "# 这里的 idx 是一个一维张量，表示要从 a 中提取的行的索引\n",
    "tf.gather(a, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成一个形状为 [4, 4] 的张量 out，其中的值是从均匀分布中随机采样的\n",
    "out = tf.random.uniform([4,4])\n",
    "\n",
    "# 创建一个一维张量 y，包含从 0 到 3 的整数\n",
    "y = tf.range(4)\n",
    "\n",
    "# 将一维张量 y 转换为独热编码，深度为 4\n",
    "y = tf.one_hot(y, depth=4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.21291801, 0.4155621 , 0.18246503, 0.49629742], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用均方误差（Mean Squared Error, MSE）计算预测值 out 和真实值 y 之间的损失\n",
    "loss = tf.keras.losses.mse(y, out)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.32681063>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算损失的均值，得到最终的标量损失值\n",
    "loss = tf.reduce_mean(loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*解释 one_hot 方法*\n",
    "`tf.one_hot` 方法用于将类别标签转换为独热编码（one-hot encoding）。独热编码是一种表示分类数据的方式，其中每个类别用一个长度为类别总数的向量表示，向量中只有一个位置为 1，其余位置为 0。\n",
    "\n",
    "在代码中：\n",
    "```python\n",
    "y = tf.range(4)\n",
    "y = tf.one_hot(y, depth=4)\n",
    "```\n",
    "- `tf.range(4)` 生成一个包含 `[0, 1, 2, 3]` 的一维张量，表示类别标签。\n",
    "- `tf.one_hot(y, depth=4)` 将这些类别标签转换为独热编码，`depth=4` 指定了编码向量的长度（即类别总数）。\n",
    "\n",
    "结果是一个形状为 `[4, 4]` 的张量，其中每一行是一个独热编码向量。例如：\n",
    "```\n",
    "[[1., 0., 0., 0.],\n",
    " [0., 1., 0., 0.],\n",
    " [0., 0., 1., 0.],\n",
    " [0., 0., 0., 1.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector\n",
    "y = w x + b <br>\n",
    "b 就是bias，<br>\n",
    "bias 是神经网络中的一个可训练参数，用于调整模型的输出。它的作用是引入一个偏移量，使模型能够更好地拟合数据，即使输入特征的值为零时，模型也能输出非零的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'kernel:0' shape=(8, 10) dtype=float32, numpy=\n",
       "array([[-7.11209774e-02,  2.53909707e-01, -3.61270636e-01,\n",
       "         1.38947845e-01, -9.94995236e-02, -3.78617704e-01,\n",
       "        -4.49406087e-01,  2.65348256e-01, -2.40454733e-01,\n",
       "         1.66623533e-01],\n",
       "       [ 2.60975778e-01, -1.01152182e-01, -4.05462801e-01,\n",
       "         4.75601912e-01, -5.03860593e-01,  3.97699177e-01,\n",
       "        -6.78905845e-02, -1.39175922e-01, -5.02817035e-01,\n",
       "         5.11494517e-01],\n",
       "       [-2.08081007e-01, -2.01056004e-02,  4.50506091e-01,\n",
       "        -5.00203192e-01, -2.14511096e-01,  1.31184161e-01,\n",
       "        -5.39737225e-01,  5.07831573e-05, -1.20794147e-01,\n",
       "         1.54117405e-01],\n",
       "       [-2.46728450e-01,  5.47217250e-01,  5.56722760e-01,\n",
       "         6.65177703e-02,  4.64597464e-01, -1.38907909e-01,\n",
       "         1.17606699e-01,  1.73900604e-01, -6.74097538e-02,\n",
       "        -3.69879603e-02],\n",
       "       [ 1.89859271e-02,  3.67379785e-02,  4.02774751e-01,\n",
       "        -5.63175678e-02, -1.90798104e-01,  7.66181946e-02,\n",
       "         4.87848401e-01,  3.65394115e-01,  2.31061459e-01,\n",
       "        -3.60448718e-01],\n",
       "       [-3.36460948e-01, -2.22990513e-02,  4.05442715e-02,\n",
       "        -3.03210795e-01,  3.24075937e-01, -3.67217153e-01,\n",
       "        -1.50241971e-01, -4.57950652e-01, -3.12748641e-01,\n",
       "        -3.20839345e-01],\n",
       "       [ 3.15901935e-01,  2.94947743e-01,  3.84488106e-02,\n",
       "        -5.60067892e-02, -4.34164554e-01,  3.51670980e-02,\n",
       "         1.07652605e-01, -2.61415273e-01, -1.33735269e-01,\n",
       "         5.19323230e-01],\n",
       "       [ 4.70930457e-01, -1.35854691e-01,  3.05877626e-01,\n",
       "         5.00601768e-01, -2.66951591e-01, -3.32304835e-02,\n",
       "         4.89606500e-01,  3.21336687e-01, -5.57440817e-01,\n",
       "         7.35951066e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "# 创建一个全连接层（Dense Layer），输出维度为10\n",
    "net = layers.Dense(10)\n",
    "\n",
    "# 构建网络层，输入形状为 (4, 8)\n",
    "net.build((4, 8))\n",
    "\n",
    "# 查看网络层的权重矩阵（kernel）\n",
    "net.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 784), dtype=float32, numpy=\n",
       "array([[-0.17807353, -1.279999  ,  0.61223817, ..., -0.5146242 ,\n",
       "        -1.1077929 , -0.40269274],\n",
       "       [ 0.6257607 , -1.2256606 ,  0.02853582, ...,  1.7323285 ,\n",
       "        -0.16644052,  0.22970657],\n",
       "       [ 1.0496666 , -0.96982205, -0.12746976, ...,  0.8918263 ,\n",
       "        -1.7534012 , -1.736392  ],\n",
       "       [ 0.5260799 , -0.28183827,  0.31058463, ..., -1.7244753 ,\n",
       "        -1.2390397 , -1.0592687 ]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4, 784])\n",
    "# tf.TensorShape([4, 784])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = layers.Dense(10)\n",
    "net.build((4,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([784, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解释 Matrix 代码和相关形状\n",
    "\n",
    "#### 1. `x = tf.random.normal([4, 784])`\n",
    "这行代码生成了一个形状为 `[4, 784]` 的张量 `x`，其中的值是从标准正态分布（均值为 0，标准差为 1）中随机采样的。  \n",
    "- `tf.random.normal` 是 TensorFlow 提供的一个函数，用于生成服从正态分布的随机数。\n",
    "- 参数 `[4, 784]` 指定了张量的形状，其中 `4` 表示有 4 行，`784` 表示每行有 784 个元素。\n",
    "- 这种形状通常用于深度学习任务中，例如处理图像数据时，每一行可能表示一个样本的特征向量。\n",
    "\n",
    "#### 2. `net` 的形状\n",
    "`net` 是一个全连接层（Dense Layer），它的输出维度为 10。  \n",
    "- 在代码中，`net.build((4, 784))` 指定了输入的形状为 `[4, 784]`，即每个输入样本有 784 个特征。\n",
    "- 由于全连接层的输出维度为 10，因此 `net` 的输出形状为 `[4, 10]`，表示 4 个样本，每个样本有 10 个输出值。\n",
    "\n",
    "#### 3. `net.kernel.shape`\n",
    "`net.kernel` 是全连接层的权重矩阵，其形状为 `[784, 10]`。  \n",
    "- 权重矩阵的形状由输入维度和输出维度决定：\n",
    "  - 输入维度为 784（每个样本的特征数）。\n",
    "  - 输出维度为 10（全连接层的输出数）。\n",
    "- 因此，`net.kernel.shape` 为 `[784, 10]`。\n",
    "\n",
    "#### 4. `net.bias.shape`\n",
    "`net.bias` 是全连接层的偏置向量，其形状为 `[10]`。  \n",
    "- 偏置向量的长度等于输出维度，即每个输出值对应一个偏置。\n",
    "- 因此，`net.bias.shape` 为 `[10]`。\n",
    "\n",
    "#### 总结\n",
    "- `x` 是输入数据，形状为 `[4, 784]`。\n",
    "- `net` 是一个全连接层，输入形状为 `[4, 784]`，输出形状为 `[4, 10]`。\n",
    "- `net.kernel` 是权重矩阵，形状为 `[784, 10]`。\n",
    "- `net.bias` 是偏置向量，形状为 `[10]`。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
