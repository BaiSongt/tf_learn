{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从numpy得到Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个numpy数组\n",
    "a = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(np.ones([2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(np.zeros([3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([1,2], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [3.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按列\n",
    "tf.convert_to_tensor([[2],[3]] ,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化为0\n",
    "tf.zeros([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.zeros([2,3])\n",
    "tf.zeros_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[9, 9, 9],\n",
       "       [9, 9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fill([2,3], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 7, 2, 3, 5, 1, 6, 4, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Permutation\n",
    "idx = tf.range(10)\n",
    "tf.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([9, 9, 5, 0, 7, 6, 5, 6, 0, 8], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([10,784])\n",
    "b = tf.random.uniform([10], maxval=10, dtype=tf.int32)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码使用了 TensorFlow 的随机数生成函数来创建两个张量 `a` 和 `b`，它们分别具有不同的形状和数据类型。以下是对每一行代码的详细解释：\n",
    "\n",
    "### 第一行代码\n",
    "```python\n",
    "a = tf.random.normal([10,784])\n",
    "```\n",
    "这行代码生成了一个形状为 `[10, 784]` 的张量 `a`，其中的值是从标准正态分布（均值为 0，标准差为 1）中随机采样的。  \n",
    "- `tf.random.normal` 是 TensorFlow 提供的一个函数，用于生成服从正态分布的随机数。\n",
    "- 参数 `[10, 784]` 指定了张量的形状，其中 `10` 表示有 10 行，`784` 表示每行有 784 个元素。这种形状通常出现在机器学习任务中，例如处理图像数据时，每一行可能表示一个样本的特征向量。\n",
    "- 默认情况下，生成的随机数的均值为 0，标准差为 1。如果需要自定义均值或标准差，可以通过 `mean` 和 `stddev` 参数进行设置。\n",
    "\n",
    "### 第二行代码\n",
    "```python\n",
    "b = tf.random.uniform([10], maxval=10, dtype=tf.int32)\n",
    "```\n",
    "这行代码生成了一个形状为 `[10]` 的张量 `b`，其中的值是从均匀分布中随机采样的整数。  \n",
    "- `tf.random.uniform` 是 TensorFlow 提供的另一个随机数生成函数，用于生成服从均匀分布的随机数。\n",
    "- 参数 `[10]` 指定了张量的形状，这里表示生成一个包含 10 个元素的一维张量。\n",
    "- `maxval=10` 指定了生成的随机数的上限（不包括 10），因此生成的整数范围是 `[0, 10)`。\n",
    "- `dtype=tf.int32` 指定了张量的数据类型为 32 位整数。如果不指定，默认生成的是浮点数。\n",
    "\n",
    "### 总结\n",
    "这两行代码通常用于深度学习任务中的数据准备阶段。例如，`a` 可以表示一个批次的输入数据，每一行是一个样本的特征向量；`b` 可以表示对应的标签，每个值是一个类别的整数编码。这种随机生成的数据常用于测试模型的输入输出逻辑或在没有真实数据时进行模拟实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 784), dtype=float32, numpy=\n",
       "array([[-0.6148276 ,  1.2829787 ,  0.7882927 , ..., -2.2798593 ,\n",
       "        -0.74909276, -0.511759  ],\n",
       "       [ 0.17948672, -0.20308031,  2.0066426 , ..., -1.0387201 ,\n",
       "        -1.1096778 , -1.8054893 ],\n",
       "       [-1.7875631 , -0.05166411,  1.5259551 , ...,  1.1795572 ,\n",
       "         0.09714194,  1.0185186 ],\n",
       "       ...,\n",
       "       [-0.42696035, -1.3934318 ,  0.55900234, ...,  1.3999722 ,\n",
       "        -0.30156636,  0.17851794],\n",
       "       [-0.2559583 , -0.47620392,  0.7227903 , ...,  0.01023562,\n",
       "         1.0936806 , -0.16867004],\n",
       "       [ 0.59773433,  1.5207876 , -0.41163495, ..., -0.80793715,\n",
       "         0.9183698 , -0.64536685]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 tf.gather 函数根据索引张量 idx 从张量 a 中提取对应的行\n",
    "# 这里的 idx 是一个一维张量，表示要从 a 中提取的行的索引\n",
    "tf.gather(a, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成一个形状为 [4, 4] 的张量 out，其中的值是从均匀分布中随机采样的\n",
    "out = tf.random.uniform([4,4])\n",
    "\n",
    "# 创建一个一维张量 y，包含从 0 到 3 的整数\n",
    "y = tf.range(4)\n",
    "\n",
    "# 将一维张量 y 转换为独热编码，深度为 4\n",
    "y = tf.one_hot(y, depth=4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.30107635, 0.4726325 , 0.58946234, 0.72581893], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用均方误差（Mean Squared Error, MSE）计算预测值 out 和真实值 y 之间的损失\n",
    "loss = tf.keras.losses.mse(y, out)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.52224755>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算损失的均值，得到最终的标量损失值\n",
    "loss = tf.reduce_mean(loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*解释 one_hot 方法*\n",
    "`tf.one_hot` 方法用于将类别标签转换为独热编码（one-hot encoding）。独热编码是一种表示分类数据的方式，其中每个类别用一个长度为类别总数的向量表示，向量中只有一个位置为 1，其余位置为 0。\n",
    "\n",
    "在代码中：\n",
    "```python\n",
    "y = tf.range(4)\n",
    "y = tf.one_hot(y, depth=4)\n",
    "```\n",
    "- `tf.range(4)` 生成一个包含 `[0, 1, 2, 3]` 的一维张量，表示类别标签。\n",
    "- `tf.one_hot(y, depth=4)` 将这些类别标签转换为独热编码，`depth=4` 指定了编码向量的长度（即类别总数）。\n",
    "\n",
    "结果是一个形状为 `[4, 4]` 的张量，其中每一行是一个独热编码向量。例如：\n",
    "```\n",
    "[[1., 0., 0., 0.],\n",
    " [0., 1., 0., 0.],\n",
    " [0., 0., 1., 0.],\n",
    " [0., 0., 0., 1.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector\n",
    "y = w x + b <br>\n",
    "b 就是bias，<br>\n",
    "bias 是神经网络中的一个可训练参数，用于调整模型的输出。它的作用是引入一个偏移量，使模型能够更好地拟合数据，即使输入特征的值为零时，模型也能输出非零的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'kernel:0' shape=(8, 10) dtype=float32, numpy=\n",
       "array([[ 0.36068094, -0.07948673,  0.0276435 , -0.14253971, -0.28167862,\n",
       "         0.14237893,  0.2732129 , -0.23863623, -0.55732465,  0.5759995 ],\n",
       "       [ 0.13967162, -0.14320442,  0.2029239 , -0.00665653, -0.565138  ,\n",
       "         0.14558953, -0.04027653, -0.2553271 , -0.28796348, -0.2214205 ],\n",
       "       [ 0.09705335,  0.5594096 ,  0.376683  ,  0.47571146, -0.5538509 ,\n",
       "        -0.07113916, -0.44284523,  0.26988274,  0.4945612 ,  0.38103002],\n",
       "       [ 0.38112062,  0.01149893,  0.09368652,  0.04835063,  0.29417896,\n",
       "        -0.20501646,  0.02059054,  0.3108908 , -0.1384399 ,  0.03814352],\n",
       "       [-0.28264078, -0.1590676 , -0.06910396, -0.25038597, -0.4724654 ,\n",
       "         0.00528073,  0.40559328, -0.50707185, -0.44553757,  0.42218727],\n",
       "       [ 0.1847592 ,  0.34623086, -0.24522942, -0.15470323,  0.04345989,\n",
       "         0.28637427,  0.4971906 , -0.3345096 , -0.07875085,  0.4888854 ],\n",
       "       [ 0.10389531, -0.05519903,  0.5169505 ,  0.4098127 ,  0.07351488,\n",
       "        -0.50368124, -0.38720518,  0.19481766,  0.08327818,  0.3610145 ],\n",
       "       [ 0.20548105, -0.5721128 , -0.36704165, -0.23279637,  0.36144477,\n",
       "         0.10125732,  0.36364156, -0.56863695,  0.23100829,  0.37983012]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "# 创建一个全连接层（Dense Layer），输出维度为10\n",
    "net = layers.Dense(10)\n",
    "\n",
    "# 构建网络层，输入形状为 (4, 8)\n",
    "net.build((4, 8))\n",
    "\n",
    "# 查看网络层的权重矩阵（kernel）\n",
    "net.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 784), dtype=float32, numpy=\n",
       "array([[ 1.0647231 , -1.3939265 , -1.170491  , ...,  0.24677674,\n",
       "        -1.2931015 , -0.7812058 ],\n",
       "       [-0.65485483,  0.46893322, -1.0090643 , ...,  0.70460606,\n",
       "        -0.72365165,  2.1718946 ],\n",
       "       [ 0.21642096,  0.2248637 ,  2.0813434 , ..., -0.34362376,\n",
       "         0.19540316, -1.043587  ],\n",
       "       [ 0.10299772, -0.75668144,  0.7103799 , ...,  0.7183968 ,\n",
       "        -0.7801946 ,  1.7664802 ]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4, 784])\n",
    "# tf.TensorShape([4, 784])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = layers.Dense(10)\n",
    "net.build((4,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([784, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解释 Matrix 代码和相关形状\n",
    "\n",
    "#### 1. `x = tf.random.normal([4, 784])`\n",
    "这行代码生成了一个形状为 `[4, 784]` 的张量 `x`，其中的值是从标准正态分布（均值为 0，标准差为 1）中随机采样的。  \n",
    "- `tf.random.normal` 是 TensorFlow 提供的一个函数，用于生成服从正态分布的随机数。\n",
    "- 参数 `[4, 784]` 指定了张量的形状，其中 `4` 表示有 4 行，`784` 表示每行有 784 个元素。\n",
    "- 这种形状通常用于深度学习任务中，例如处理图像数据时，每一行可能表示一个样本的特征向量。\n",
    "\n",
    "#### 2. `net` 的形状\n",
    "`net` 是一个全连接层（Dense Layer），它的输出维度为 10。  \n",
    "- 在代码中，`net.build((4, 784))` 指定了输入的形状为 `[4, 784]`，即每个输入样本有 784 个特征。\n",
    "- 由于全连接层的输出维度为 10，因此 `net` 的输出形状为 `[4, 10]`，表示 4 个样本，每个样本有 10 个输出值。\n",
    "\n",
    "#### 3. `net.kernel.shape`\n",
    "`net.kernel` 是全连接层的权重矩阵，其形状为 `[784, 10]`。  \n",
    "- 权重矩阵的形状由输入维度和输出维度决定：\n",
    "  - 输入维度为 784（每个样本的特征数）。\n",
    "  - 输出维度为 10（全连接层的输出数）。\n",
    "- 因此，`net.kernel.shape` 为 `[784, 10]`。\n",
    "\n",
    "#### 4. `net.bias.shape`\n",
    "`net.bias` 是全连接层的偏置向量，其形状为 `[10]`。  \n",
    "- 偏置向量的长度等于输出维度，即每个输出值对应一个偏置。\n",
    "- 因此，`net.bias.shape` 为 `[10]`。\n",
    "\n",
    "#### 总结\n",
    "- `x` 是输入数据，形状为 `[4, 784]`。\n",
    "- `net` 是一个全连接层，输入形状为 `[4, 784]`，输出形状为 `[4, 10]`。\n",
    "- `net.kernel` 是权重矩阵，形状为 `[784, 10]`。\n",
    "- `net.bias` 是偏置向量，形状为 `[10]`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量 x:\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 使用 tf.reshape 函数改变张量的形状\n",
    "# tf.reshape 是 TensorFlow 中用于改变张量形状的函数，但不会改变数据本身的顺序。\n",
    "\n",
    "# 创建一个形状为 [2, 3] 的张量\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"原始张量 x:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "重塑后的张量 x_reshaped (形状 [3, 2]):\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 将张量 x 重塑为形状 [3, 2]\n",
    "x_reshaped = tf.reshape(x, [3, 2])\n",
    "print(\"\\n重塑后的张量 x_reshaped (形状 [3, 2]):\")\n",
    "print(x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "重塑后的张量 x_flattened (一维张量):\n",
      "tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 将张量 x 重塑为一维张量\n",
    "# 注意：-1 表示自动推断维度大小，前提是其他维度的大小已知且总元素数量不变。\n",
    "x_flattened = tf.reshape(x, [-1])\n",
    "print(\"\\n重塑后的张量 x_flattened (一维张量):\")\n",
    "print(x_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "重塑后的张量 x_reshaped_1_6 (形状 [1, 6]):\n",
      "tf.Tensor([[1 2 3 4 5 6]], shape=(1, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 将张量 x 重塑为形状 [1, 6]\n",
    "x_reshaped_1_6 = tf.reshape(x, [1, 6])\n",
    "print(\"\\n重塑后的张量 x_reshaped_1_6 (形状 [1, 6]):\")\n",
    "print(x_reshaped_1_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 2, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal((4,3,2,1))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 3, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.transpose(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_3d_trans = tf.transpose(x)\n",
    "tf_3d_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_3d_trans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
