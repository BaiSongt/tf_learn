{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b366e4",
   "metadata": {},
   "source": [
    "# 数据统计\n",
    "- Vector norm\n",
    "- reduce_min max mean\n",
    "- argmin argmax\n",
    "- equal\n",
    "- accuracy\n",
    "- unique\n",
    "---\n",
    "## TensorFlow 中常用的 Vector Norm\n",
    "\n",
    "在 TensorFlow 中，`tf.norm` 函数可以用来计算向量或矩阵的范数。以下是常用的向量范数及其公式：\n",
    "\n",
    "#### 1. L1 范数 (Manhattan Norm)\n",
    "L1 范数是向量中所有元素绝对值的和，公式如下：\n",
    "$$\n",
    "\\|x\\|_1 = \\sum_{i=1}^n |x_i|\n",
    "$$\n",
    "\n",
    "在 TensorFlow 中可以通过以下方式计算：\n",
    "```python\n",
    "tf.norm(x, ord=1)\n",
    "```\n",
    "\n",
    "#### 2. L2 范数 (Euclidean Norm)\n",
    "L2 范数是向量中所有元素平方和的平方根，公式如下：\n",
    "$$\n",
    "\\|x\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}\n",
    "$$\n",
    "\n",
    "在 TensorFlow 中可以通过以下方式计算：\n",
    "```python\n",
    "tf.norm(x, ord=2)\n",
    "```\n",
    "\n",
    "#### 3. 无穷范数 (Infinity Norm)\n",
    "无穷范数是向量中元素绝对值的最大值，公式如下：\n",
    "$$\n",
    "\\|x\\|_\\infty = \\max(|x_1|, |x_2|, \\dots, |x_n|)\n",
    "$$\n",
    "\n",
    "在 TensorFlow 中可以通过以下方式计算：\n",
    "```python\n",
    "tf.norm(x, ord=np.inf)\n",
    "```\n",
    "\n",
    "#### 4. p 范数\n",
    "p 范数是向量中所有元素绝对值的 p 次方和的 1/p 次方，公式如下：\n",
    "$$\n",
    "\\|x\\|_p = \\left(\\sum_{i=1}^n |x_i|^p\\right)^{\\frac{1}{p}}\n",
    "$$\n",
    "\n",
    "在 TensorFlow 中可以通过以下方式计算：\n",
    "```python\n",
    "tf.norm(x, ord=p)\n",
    "```\n",
    "\n",
    "#### 示例代码\n",
    "以下是一个计算不同范数的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "496d3900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm: 6.0\n",
      "L2 Norm: 3.7416575\n",
      "Infinity Norm: 3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = tf.constant([1.0, -2.0, 3.0])\n",
    "\n",
    "# L1 范数\n",
    "l1_norm = tf.norm(x, ord=1)\n",
    "\n",
    "# L2 范数\n",
    "l2_norm = tf.norm(x, ord=2)\n",
    "\n",
    "# 无穷范数\n",
    "inf_norm = tf.norm(x, ord=np.inf)\n",
    "\n",
    "print(\"L1 Norm:\", l1_norm.numpy())\n",
    "print(\"L2 Norm:\", l2_norm.numpy())\n",
    "print(\"Infinity Norm:\", inf_norm.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146473ec",
   "metadata": {},
   "source": [
    "----\n",
    "## reduce_min、reduce_max 和 reduce_mean\n",
    "\n",
    "在 TensorFlow 中，`tf.reduce_min`、`tf.reduce_max` 和 `tf.reduce_mean` 是常用的操作，用于对张量进行降维操作，计算最小值、最大值和平均值。以下是它们的介绍、公式和示例代码：\n",
    "\n",
    "## 1. `tf.reduce_min`\n",
    "`tf.reduce_min` 用于计算张量沿指定维度的最小值。\n",
    "\n",
    "### 公式\n",
    "给定张量 $ x $ ，沿维度 $ d $  计算最小值：\n",
    "$$\n",
    "\\text{reduce\\_min}(x, d) = \\min(x, \\text{axis}=d)\n",
    "$$\n",
    "\n",
    "### 示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "013d8cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce Min (axis=0): [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "min_value = tf.reduce_min(x, axis=0)  # 沿列计算最小值\n",
    "print(\"Reduce Min (axis=0):\", min_value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece62a28",
   "metadata": {},
   "source": [
    "## 2. `tf.reduce_max`\n",
    "`tf.reduce_max` 用于计算张量沿指定维度的最大值。\n",
    "\n",
    "### 公式\n",
    "给定张量 $ x $ ，沿维度 $ d $  计算最大值：\n",
    "$$\n",
    "\\text{reduce\\_max}(x, d) = \\max(x, \\text{axis}=d)\n",
    "$$\n",
    "\n",
    "### 示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eea48fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce Max (axis=1): [3 6]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "max_value = tf.reduce_max(x, axis=1)  # 沿行计算最大值\n",
    "print(\"Reduce Max (axis=1):\", max_value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac354a30",
   "metadata": {},
   "source": [
    "## 3. `tf.reduce_mean`\n",
    "`tf.reduce_mean` 用于计算张量沿指定维度的平均值。\n",
    "\n",
    "### 公式\n",
    "给定张量 $ x $ ，沿维度 $ d $  计算平均值：\n",
    "$$\n",
    "\\text{reduce\\_mean}(x, d) = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$\n",
    "\n",
    "### 示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c8f0a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce Mean (global): 3\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "mean_value = tf.reduce_mean(x, axis=None)  # 计算全局平均值\n",
    "print(\"Reduce Mean (global):\", mean_value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aef29a",
   "metadata": {},
   "source": [
    "### 总结\n",
    "- `tf.reduce_min`：计算最小值\n",
    "- `tf.reduce_max`：计算最大值\n",
    "- `tf.reduce_mean`：计算平均值\n",
    "\n",
    "通过指定 `axis` 参数，可以控制降维的方向。如果不指定 `axis`，则对整个张量进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e79347",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "---\n",
    "## TensorFlow 中常用的 `tf.argmax` 和 `tf.argmin`\n",
    "\n",
    "在 TensorFlow 中，`tf.argmax` 和 `tf.argmin` 是常用的操作，用于计算张量沿指定维度的最大值或最小值的索引。以下是它们的介绍、公式和示例代码：\n",
    "\n",
    "### 1. `tf.argmax`\n",
    "`tf.argmax` 用于计算张量沿指定维度的最大值的索引。\n",
    "\n",
    "#### 公式\n",
    "给定张量 $ x $ ，沿维度 $ d $ 计算最大值的索引：\n",
    "$$\n",
    "\\text{argmax}(x, d) = \\text{index of } \\max(x, \\text{axis}=d)\n",
    "$$\n",
    "\n",
    "#### 示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48f97099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42c7b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argmax (axis=0): [1 1 1]\n",
      "Argmax (axis=1): [2 2]\n"
     ]
    }
   ],
   "source": [
    "# 沿列计算最大值的索引\n",
    "argmax_col = tf.argmax(x, axis=0)\n",
    "print(\"Argmax (axis=0):\", argmax_col.numpy())\n",
    "\n",
    "# 沿行计算最大值的索引\n",
    "argmax_row = tf.argmax(x, axis=1)\n",
    "print(\"Argmax (axis=1):\", argmax_row.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280b8df",
   "metadata": {},
   "source": [
    "### 2. `tf.argmin`\n",
    "`tf.argmin` 用于计算张量沿指定维度的最小值的索引。\n",
    "\n",
    "#### 公式\n",
    "给定张量 $ x $ ，沿维度 $ d $ 计算最小值的索引：\n",
    "$$\n",
    "\\text{argmin}(x, d) = \\text{index of } \\min(x, \\text{axis}=d)\n",
    "$$\n",
    "\n",
    "#### 示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f7a26c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argmin (axis=0): [0 0 0]\n",
      "Argmin (axis=1): [0 0]\n"
     ]
    }
   ],
   "source": [
    "# 沿列计算最小值的索引\n",
    "argmin_col = tf.argmin(x, axis=0)\n",
    "print(\"Argmin (axis=0):\", argmin_col.numpy())\n",
    "\n",
    "# 沿行计算最小值的索引\n",
    "argmin_row = tf.argmin(x, axis=1)\n",
    "print(\"Argmin (axis=1):\", argmin_row.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05474b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 输出示例\n",
    "# 假设张量 `x` 的值为：\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e369f",
   "metadata": {},
   "source": [
    "### 总结\n",
    "- `tf.argmin` 用于计算最小值的索引。\n",
    "- 通过指定 `axis` 参数，可以控制计算的方向：\n",
    "  - `axis=0` 表示沿列计算。\n",
    "  - `axis=1` 表示沿行计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1822df0f",
   "metadata": {},
   "source": [
    "---\n",
    "## TensorFlow `tf.equal`\n",
    "\n",
    "在 TensorFlow 中，`tf.equal` 是一个用于比较两个张量是否相等的操作。它会逐元素比较两个张量的值，并返回一个布尔类型的张量，表示每个位置上的值是否相等。\n",
    "\n",
    "### 公式\n",
    "给定两个张量 $ x $ 和 $ y $，`tf.equal` 的计算公式为：\n",
    "$$\n",
    "\\text{equal}(x, y) = \n",
    "\\begin{cases} \n",
    "\\text{True}, & \\text{if } x_i = y_i \\\\\n",
    "\\text{False}, & \\text{if } x_i \\neq y_i\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 示例代码\n",
    "以下是一个使用 `tf.equal` 的示例代码：\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# 定义两个张量\n",
    "x = tf.constant([1, 2, 3, 4])\n",
    "y = tf.constant([1, 0, 3, 0])\n",
    "\n",
    "# 比较两个张量是否相等\n",
    "result = tf.equal(x, y)\n",
    "\n",
    "print(\"Tensor x:\", x.numpy())\n",
    "print(\"Tensor y:\", y.numpy())\n",
    "print(\"Equal result:\", result.numpy())\n",
    "```\n",
    "\n",
    "### 输出示例\n",
    "假设 `x` 和 `y` 的值分别为 `[1, 2, 3, 4]` 和 `[1, 0, 3, 0]`，则输出为：\n",
    "```\n",
    "Tensor x: [1 2 3 4]\n",
    "Tensor y: [1 0 3 0]\n",
    "Equal result: [ True False  True False]\n",
    "```\n",
    "\n",
    "### 总结\n",
    "- `tf.equal` 是逐元素比较操作，返回布尔类型的张量。\n",
    "- 它常用于条件判断或过滤操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e9855",
   "metadata": {},
   "source": [
    "### 准确率 (Accuracy)\n",
    "\n",
    "在机器学习和深度学习中，**准确率 (Accuracy)** 是一种常用的评估指标，用于衡量模型预测的正确性。它表示模型预测正确的样本数量占总样本数量的比例。\n",
    "\n",
    "#### 公式\n",
    "给定真实标签 $ y_{\\text{true}} $ 和预测标签 $ y_{\\text{pred}} $，准确率的计算公式为：\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "$$\n",
    "\n",
    "或者可以表示为：\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\sum_{i=1}^N \\mathbb{1}(y_{\\text{true}, i} = y_{\\text{pred}, i})}{N}\n",
    "$$\n",
    "其中：\n",
    "- $ N $ 是样本总数。\n",
    "- $ \\mathbb{1}(\\cdot) $ 是指示函数，当条件为真时取值为 1，否则为 0。\n",
    "\n",
    "\n",
    "#### 总结\n",
    "- **准确率** 是衡量模型性能的重要指标，适用于分类任务。\n",
    "- 在 TensorFlow 中，可以通过 `tf.equal` 和 `tf.reduce_mean` 结合实现准确率的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcba55e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_predictions  tf.Tensor([ True  True  True False  True  True], shape=(6,), dtype=bool)\n",
      "Accuracy: 0.8333333\n",
      "Total Count : (6,)\n",
      "Right Count : 5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 假设真实标签 (y_true) 和预测标签 (y_pred)\n",
    "y_true = tf.constant([1, 0, 1, 1, 0, 1])  # 真实值\n",
    "y_pred = tf.constant([1, 0, 1, 0, 0, 1])  # 预测值\n",
    "\n",
    "# 逐元素比较预测值和真实值是否相等\n",
    "correct_predictions = tf.equal(y_true, y_pred)\n",
    "\n",
    "print(\"correct_predictions \",correct_predictions)\n",
    "\n",
    "# 将布尔值转换为浮点数，并计算平均值\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "count = tf.reduce_sum(tf.cast(correct_predictions, tf.int32))\n",
    "\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Total Count :\", y_true.shape)\n",
    "print(\"Right Count :\", count.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6bb5d",
   "metadata": {},
   "source": [
    "#### 输出示例\n",
    "假设真实标签和预测标签分别为 `[1, 0, 1, 1, 0, 1]` 和 `[1, 0, 1, 0, 0, 1]`，则输出为：\n",
    "```\n",
    "Accuracy: 0.8333333\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3746f97a",
   "metadata": {},
   "source": [
    "---\n",
    "## TensorFlow 中的 `tf.unique`\n",
    "\n",
    "在 TensorFlow 中，`tf.unique` 是一个用于找出张量中唯一元素的操作。它会返回一个包含唯一值的张量，以及每个输入值在唯一值张量中的索引。\n",
    "\n",
    "### 公式\n",
    "给定一个张量 $ x $，`tf.unique` 的计算公式为：\n",
    "$$\n",
    "\\text{unique}(x) = \\{x_i \\mid x_i \\text{ 是 } x \\text{ 中的唯一值}\\}\n",
    "$$\n",
    "\n",
    "返回结果包括：\n",
    "1. 唯一值张量 $ y $。\n",
    "2. 每个输入值在唯一值张量中的索引 $ idx $。\n",
    "\n",
    "### 示例代码\n",
    "以下是一个使用 `tf.unique` 的示例代码：\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# 定义一个张量\n",
    "x = tf.constant([1, 2, 2, 3, 4, 4, 5])\n",
    "\n",
    "# 计算唯一值及其索引\n",
    "unique_values, indices = tf.unique(x)\n",
    "\n",
    "print(\"Original Tensor:\", x.numpy())\n",
    "print(\"Unique Values:\", unique_values.numpy())\n",
    "print(\"Indices:\", indices.numpy())\n",
    "```\n",
    "\n",
    "### 输出示例\n",
    "假设输入张量为 `[1, 2, 2, 3, 4, 4, 5]`，则输出为：\n",
    "```\n",
    "Original Tensor: [1 2 2 3 4 4 5]\n",
    "Unique Values: [1 2 3 4 5]\n",
    "Indices: [0 1 1 2 3 3 4]\n",
    "```\n",
    "\n",
    "### 总结\n",
    "- `tf.unique` 用于提取张量中的唯一值。\n",
    "- 返回的索引可以用来重建原始张量或映射到唯一值张量。\n",
    "- 它常用于数据去重或分类任务中的预处理步骤。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
