(60000, 28, 28) (60000,)
(10000, 28, 28) (10000,)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 dense (Dense)               (None, 256)               200960

 dense_1 (Dense)             (None, 128)               32896

 dense_2 (Dense)             (None, 64)                8256

 dense_3 (Dense)             (None, 32)                2080

 dense_4 (Dense)             (None, 10)                330

=================================================================
Total params: 244,522
Trainable params: 244,522
Non-trainable params: 0
_________________________________________________________________
2025-04-13 15:15:36.122024: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype uint8 and shape [60000,28,28]
         [[{{node Placeholder/_0}}]]
2025-04-13 15:15:36.122146: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [60000]
         [[{{node Placeholder/_1}}]]
2025-04-13 15:15:36.125643: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
batch:  (128, 28, 28) (128,)
/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)
0 0 loss:  2.315006732940674 0.13043645024299622
0 100 loss:  0.5209791660308838 17.25585174560547
0 200 loss:  0.5201083421707153 20.21004295349121
0 300 loss:  0.44844257831573486 21.97426986694336
0 400 loss:  0.48985153436660767 18.026845932006836
1 0 loss:  0.44861555099487305 19.148502349853516
1 100 loss:  0.5869271159172058 18.000640869140625
1 200 loss:  0.3024892807006836 19.23853302001953
1 300 loss:  0.4022924304008484 27.472179412841797
1 400 loss:  0.33653897047042847 19.17593002319336
2 0 loss:  0.32449400424957275 23.50838851928711
2 100 loss:  0.31278470158576965 26.231674194335938
2 200 loss:  0.27583861351013184 22.55329132080078
2 300 loss:  0.30831998586654663 22.33948516845703
2 400 loss:  0.32617807388305664 22.71673583984375
3 0 loss:  0.2802181541919708 24.526599884033203
3 100 loss:  0.26445162296295166 33.209407806396484
3 200 loss:  0.30402320623397827 28.695091247558594
3 300 loss:  0.40085047483444214 30.029327392578125
3 400 loss:  0.2600114941596985 28.601423263549805
4 0 loss:  0.2274439036846161 30.245824813842773
4 100 loss:  0.307145893573761 35.56993865966797
4 200 loss:  0.2657628357410431 29.327350616455078
4 300 loss:  0.33252620697021484 35.00403594970703
4 400 loss:  0.248577281832695 35.946353912353516
5 0 loss:  0.3958509564399719 31.775081634521484
5 100 loss:  0.3159571886062622 41.13714599609375
5 200 loss:  0.2155592292547226 43.085689544677734
5 300 loss:  0.33077239990234375 31.48805809020996
5 400 loss:  0.24966171383857727 40.738285064697266
6 0 loss:  0.16432687640190125 49.08995819091797
6 100 loss:  0.21357101202011108 41.640113830566406
6 200 loss:  0.2342367172241211 50.19001007080078
6 300 loss:  0.21874569356441498 37.78859329223633
6 400 loss:  0.24439510703086853 53.086753845214844
7 0 loss:  0.22978898882865906 38.3966178894043
7 100 loss:  0.22658990323543549 56.43171691894531
7 200 loss:  0.33399444818496704 55.121131896972656
7 300 loss:  0.24274346232414246 49.77393341064453
7 400 loss:  0.10344098508358002 52.42950439453125
8 0 loss:  0.2248999923467636 54.25788879394531
8 100 loss:  0.23600167036056519 53.822689056396484
8 200 loss:  0.2078966200351715 54.46211624145508
8 300 loss:  0.20253950357437134 59.06679153442383
8 400 loss:  0.16265566647052765 59.874244689941406
9 0 loss:  0.14068907499313354 51.19681930541992
9 100 loss:  0.3143998086452484 66.36976623535156
9 200 loss:  0.27611392736434937 59.82480239868164
9 300 loss:  0.24246002733707428 61.179359436035156
9 400 loss:  0.2577056586742401 58.42079162597656
10 0 loss:  0.2490982711315155 60.79267883300781
10 100 loss:  0.21265290677547455 56.71714401245117
10 200 loss:  0.18039032816886902 66.61279296875
10 300 loss:  0.22173327207565308 65.62283325195312
10 400 loss:  0.2549865245819092 68.64248657226562
11 0 loss:  0.21597687900066376 50.72260284423828
11 100 loss:  0.1935151070356369 68.84137725830078
11 200 loss:  0.23288875818252563 83.05934143066406
11 300 loss:  0.11338309198617935 85.10308837890625
11 400 loss:  0.20073935389518738 69.96702575683594
12 0 loss:  0.2145237773656845 72.53190612792969
12 100 loss:  0.25766125321388245 84.20610046386719
12 200 loss:  0.1210380345582962 64.01397705078125
12 300 loss:  0.12677481770515442 87.18406677246094
12 400 loss:  0.26074373722076416 69.68995666503906
13 0 loss:  0.16859199106693268 68.46317291259766
13 100 loss:  0.2555730938911438 63.69873809814453
13 200 loss:  0.2079433649778366 73.96805572509766
13 300 loss:  0.1973513662815094 74.97171020507812
13 400 loss:  0.14829154312610626 104.10792541503906
14 0 loss:  0.17545321583747864 85.20472717285156
14 100 loss:  0.14532878994941711 102.62124633789062
14 200 loss:  0.18077576160430908 80.55644989013672
14 300 loss:  0.2140357792377472 69.91483306884766
14 400 loss:  0.2138400673866272 79.74037170410156
15 0 loss:  0.06947566568851471 116.6705551147461
15 100 loss:  0.2535313367843628 108.63760375976562
15 200 loss:  0.25984716415405273 96.89372253417969
15 300 loss:  0.2499287873506546 87.83049011230469
15 400 loss:  0.2290818989276886 115.30856323242188
16 0 loss:  0.1511257290840149 103.43765258789062
16 100 loss:  0.20690159499645233 97.51239776611328
16 200 loss:  0.13972130417823792 111.3240966796875
16 300 loss:  0.18748942017555237 87.43643188476562
16 400 loss:  0.22236672043800354 114.47284698486328
17 0 loss:  0.14582476019859314 102.1099853515625
17 100 loss:  0.2382834553718567 99.7674560546875
17 200 loss:  0.2349224090576172 78.96185302734375
17 300 loss:  0.13139088451862335 141.4854736328125
17 400 loss:  0.1717488020658493 154.48043823242188
18 0 loss:  0.291584849357605 95.02450561523438
18 100 loss:  0.13971799612045288 96.37625122070312
18 200 loss:  0.16569051146507263 94.08869934082031
18 300 loss:  0.143705815076828 100.78752899169922
18 400 loss:  0.17592543363571167 109.85516357421875
19 0 loss:  0.16400451958179474 140.88247680664062
19 100 loss:  0.15561705827713013 137.22789001464844
19 200 loss:  0.18757617473602295 133.90325927734375
19 300 loss:  0.20549723505973816 87.93231964111328
19 400 loss:  0.13248029351234436 105.6399154663086
20 0 loss:  0.11629215627908707 130.04690551757812
20 100 loss:  0.15989039838314056 121.09797668457031
20 200 loss:  0.19636821746826172 125.39974975585938
20 300 loss:  0.17478454113006592 130.81939697265625
20 400 loss:  0.16356617212295532 125.33003234863281
21 0 loss:  0.1988433599472046 118.40400695800781
21 100 loss:  0.19766660034656525 177.65963745117188
21 200 loss:  0.08147601783275604 163.88235473632812
21 300 loss:  0.09791219234466553 129.85342407226562
21 400 loss:  0.1871110200881958 116.77429962158203
22 0 loss:  0.1585482805967331 148.31390380859375
22 100 loss:  0.15457209944725037 163.19137573242188
22 200 loss:  0.08983664214611053 160.5137939453125
22 300 loss:  0.10943221300840378 147.96897888183594
22 400 loss:  0.14015035331249237 131.59608459472656
23 0 loss:  0.13527178764343262 130.9254150390625
23 100 loss:  0.1068560928106308 181.06240844726562
23 200 loss:  0.1842813789844513 157.47109985351562
23 300 loss:  0.3191220760345459 144.03858947753906
23 400 loss:  0.1727166324853897 138.05447387695312
24 0 loss:  0.11312750726938248 135.612548828125
24 100 loss:  0.14001742005348206 201.98828125
24 200 loss:  0.15403154492378235 184.309326171875
24 300 loss:  0.1348617672920227 174.86538696289062
24 400 loss:  0.0753081887960434 144.1342010498047
25 0 loss:  0.2209044098854065 170.90272521972656
25 100 loss:  0.175869882106781 168.376953125
25 200 loss:  0.1527264267206192 193.08383178710938
25 300 loss:  0.1576981246471405 192.38430786132812
25 400 loss:  0.17765900492668152 174.68008422851562
26 0 loss:  0.15302494168281555 173.06661987304688
26 100 loss:  0.10846517980098724 189.9879150390625
26 200 loss:  0.09728311747312546 130.15969848632812
26 300 loss:  0.1309361606836319 200.4906005859375
26 400 loss:  0.12856771051883698 160.9048309326172
27 0 loss:  0.16412866115570068 172.68539428710938
27 100 loss:  0.08108498156070709 172.07186889648438
27 200 loss:  0.1089525818824768 168.81655883789062
27 300 loss:  0.13814818859100342 197.87777709960938
27 400 loss:  0.09268705546855927 170.69618225097656
28 0 loss:  0.1322733461856842 202.3290557861328
28 100 loss:  0.17757940292358398 186.87625122070312
28 200 loss:  0.13168245553970337 236.0291748046875
28 300 loss:  0.1244472786784172 230.67562866210938
28 400 loss:  0.07396494597196579 172.525146484375
29 0 loss:  0.18673713505268097 160.48768615722656
29 100 loss:  0.1463460773229599 189.89791870117188
29 200 loss:  0.16958381235599518 188.19244384765625
29 300 loss:  0.09152022749185562 280.7417907714844
29 400 loss:  0.08048006892204285 253.16575622558594
2025-04-13 15:16:33.366362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [60000]
         [[{{node Placeholder/_1}}]]
acc:  0.9533666666666667
