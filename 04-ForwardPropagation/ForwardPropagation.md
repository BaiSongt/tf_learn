# 前向传播理论基础

前向传播（Forward Propagation）是神经网络中数据从输入到输出的计算过程。在这个过程中，输入数据依次通过网络的每一层，最终生成预测结果。前向传播的核心是通过数学公式计算每一层的输出。

## 1. 神经网络的基本组成

一个神经网络通常由以下部分组成：
- **输入层**：接收输入数据。
- **隐藏层**：对数据进行处理，包含权重、偏置和激活函数。
- **输出层**：生成最终的预测结果。

## 2. 前向传播的基本公式

在神经网络中，每一层的计算可以分为两步：

1. **线性变换**：将输入与权重相乘并加上偏置，计算公式为：
  $$
  z = W \cdot x + b
  $$
  其中：
  -  $W$  是权重矩阵。
  -  $x$  是输入向量。
  -  $b$  是偏置向量。
  -  $z$  是线性变换的结果。

2. **激活函数**：对线性变换的结果  $z$  应用激活函数  $f(z)$ ，得到输出：
  $$
  a = f(z)
  $$

常见的激活函数包括：
- **Sigmoid 函数**：
  $$
  f(z) = \frac{1}{1 + e^{-z}}
  $$
- **ReLU 函数**：
  $$
  f(z) = \max(0, z)
  $$
- **Tanh 函数**：
  $$
  f(z) = \tanh(z)
  $$

## 3. 多层神经网络的前向传播

对于多层神经网络，前向传播是逐层计算的。假设网络有  $L$  层，每一层的计算公式如下：

1. 第  $l$  层的线性变换：
  $$
  z^{[l]} = W^{[l]} \cdot a^{[l-1]} + b^{[l]}
  $$
  其中：
  -  $a^{[l-1]}$  是上一层的输出（激活值）。
  -  $W^{[l]}$  和  $b^{[l]}$  是当前层的权重和偏置。

2. 应用激活函数：
  $$
  a^{[l]} = f(z^{[l]})
  $$

最终，第  $L$  层的输出  $a^{[L]}$  就是网络的预测结果。

## 4. 总结

前向传播是神经网络的核心计算过程，通过逐层计算，网络能够从输入数据中提取特征并生成输出结果。理解前向传播的基本原理是学习深度学习的基础。
